<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Workshop on the Future of Computing Architectures (FOCA 2022)</title>

    <!-- css -->
    <link rel="stylesheet" href="bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="bower_components/ionicons/css/ionicons.min.css">
    <link rel="stylesheet" href="assets/css/main.css">
	<style>
		.popover {
		        max-width: 80% !important;
		    }
	</style>
</head>
<body data-spy="scroll" data-target="#site-nav">
    <nav id="site-nav" class="navbar navbar-fixed-top navbar-custom">
        <div class="container">
            <div class="navbar-header">

                <!-- logo -->
                <div class="site-branding">
                    <a class="logo" href="index.html">
                        
                        <!-- logo image  -->
                        <!-- <img src="assets/images/logo.png" alt="Logo"> -->
                        FOCA 2022
                    </a>
                </div>

                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-items" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>

            </div><!-- /.navbar-header -->

            <div class="collapse navbar-collapse" id="navbar-items">
                <ul class="nav navbar-nav navbar-right">

                    <!-- navigation menu -->
                    <li class="active"><a data-scroll href="#about">About</a></li>
                    <li><a data-scroll href="#speakers">Speakers</a></li>                  
                    <li><a data-scroll href="#program">Program</a></li>                  
                    <li><a data-scroll href="#org">Organizers</a></li>                  
                
                </ul>
            </div>
        </div><!-- /.container -->
    </nav>

    <header id="site-header" class="site-header valign-center"> 
        <div class="intro">

            <p>October 29<sup>th</sup> 2021 &mdash; "Virtual Edition"</p>
            
            <h1 class="display-1">FOCA 2022</h1>
            <h1>6<sup>th</sup> Workshop on the Future of Computing Architectures</h1>
            
            <p>IBM Research</p>
            
            <!--
            <a class="btn btn-white" data-scroll href="#about">Contribute Now</a>

            <a class="btn btn-white" data-scroll href="#registration">Register Now</a>
            -->
        
        </div>
    </header>

    <section id="about" class="section about">
        <div class="container">
            <div class="row">
                <div class="col-sm-6">

                    <h3 class="section-title">About</h3>
                    
                    <p>
                    The <b>6<sup>th</sup> Workshop on the Future of Computing Architectures (FOCA 2022)</b> will be held on Friday October 29th
                    , 2021 <strong>in a virtual format</strong>. This event is a full-day workshop  that provides a forum for invited
					students in a broad range of fields covering all aspects of architectures for the  future of computing. Invited students
					are expected to showcase their work and interact with their peers and members of  the IBM Research community.<br><br>

                    The topics covered by FOCA 2022 include but are not limited to:
                    </p>
                    
                    <ul class="list-arrow-right">
                        <li>Architectures for artificial intelligence / machine learning.</li>
                        <li>Security- and reliability-aware architectures.</li>
                        <li>Architectures for cloud, high-performance computing, and data centers.</li>
                        <li>Next-generation memory architectures.</li>
                        <li>Parallel architectures.</li>
                        <li>Power‐efficient architectures and systems.</li>
                        <li>Embedded, IoT, reconfigurable, and heterogeneous architectures.</li>
                        <li>Architectures for emerging technology and applications.</li>
                        <li>Quantum computing, quantum circuit optimization.</li>
                    </ul>
                    
                    <br>

                    <h3 class="section-title">Past Editions</h3>
                        
                    <ul class="list-arrow-right">
                        <li><a href="https://augustojv.github.io/foca-workshop-2020" target="_blank">2020</a></li>
                        <li><a href="https://augustojv.github.io/foca-workshop-2019" target="_blank">2019</a></li>
                        <li><a href="https://researcher.watson.ibm.com/researcher/view_group.php?id=9671" target="_blank">2018</a></li>
                        <li><a href="https://researcher.watson.ibm.com/researcher/view_group.php?id=8187" target="_blank">2017</a></li>
                        <li><a href="http://researcher.watson.ibm.com/researcher/view_group.php?id=7424" target="_blank">2016</a></li>
                    </ul>

                    <br>
                    
                    <h3 class="section-title">Contact</h3>
                        
                    <ul class="list-arrow-right">
                    <li><a href="mailto:info@foca-workshop.org">info@foca-workshop.org</a></li> 
                    </ul>
                </div><!-- /.col-sm-6 -->

                <div class="col-sm-6">

                    <h3 class="section-title multiple-title">Organizing Committee</h3>
                    <p>
					<ul class="list-arrow-right">
                        <li>Sandhya Koteshwara</li>
                        <li>Karthik Swaminathan</li>
                        <li>David Trilla</li>
                        <li>Augusto Vega</li>
					</ul>
                    </p>

                    <h3 class="section-title multiple-title">Selection Committee</h3>
                   <p>
					  <ul class="list-arrow-right">
						<li>Alper Buyuktosunoglu</li>
						<li>Anne Gattiker</li>
            <li>Anthony Saporito</li>
            <li>Ashish Ranjan</li>
						<li>Bishwaranjan Bhattacharjee</li>
            <li>Brian Prasky</li>
            <li>Bruce D'Amora</li>
						<li>Bulent Abali</li>
            <li>Chia-yu Chen</li>
            <li>Christine Ouyang</li>
						<li>Hubertus Franke</li>
            <li>Jaime Moreno</li>
            <li>Jane Bartik</li>
						<li>Jinjun Xiong</li>
						<li>John-David Wellman</li>
            <li>Kailash Gopalakrishnan</li>
						<li>Kaoutar el Maghraoui</li>
            <li>Karthick Rajamani</li>
            <li>Madhavi G Valluri</li>
						<li>Manoj Kumar</li>
            <li>Martin Cochet</li>
            <li>Matthew Zeigler</li>
            <li>Monodeep Kar</li>
						<li>Nagu Dhanwada</li>
            <li>Paul Crumley</li>
            <li>Peilin Song</li>
            <li>Prabhakar Kudva</li>
            <li>Pradip Bose</li>
            <li>Prasanth Chatarasi</li>
						<li>Ravi Nair</li>
            <li>Sameh Asaad</li>
            <li>Sanchari Sen</li>
            <li>Sunil Shukla</li>
						<li>Swagath Venkataramani</li>
            <li>Xiaoxiong Gu</li>
            <li>Xinyu Que</li>
            </ul> 
                    </p>


                </div><!-- /.col-sm-6 -->
            </div><!-- /.row -->
        </div><!-- /.container -->
    </section>

    <section id="links" class="section bg-image-2 facts ">
        <div class="container">
            <div class="row">
				<div class="col-md-12">
                    <h3 class="section-title">Interesting Links</h3>
                </div>
				<div class="col-md-3">
                    <p>The <a href="http://www.computerhistory.org/timeline/ai-robotics/" rel="nofollow" target="_blank">AI and Robotics Timeline</a> from 1939 to date.</p>
                </div><div class="col-md-3">
                    <p>The <a href="https://www.research.ibm.com/ibm-q/technology/experience/" rel="nofollow" 
                        target="_blank">IBM Q Experience</a> to try a quantum computer online.</p>
                </div><div class="col-md-3">
                    <p>IBM Watson in action in this <a href="https://visual-recognition-demo.mybluemix.net" rel="nofollow" target="_blank">on-line demo</a> using deep learning.</p>
                </div><div class="col-md-3">
                    <p>The <a href="http://research.ibm.com/cognitive-computing/" rel="nofollow" target="_blank">AI Portal</a> with the latest IBM research activities.</p>
                </div>
          </div>
        </div>
    </section>
    
    <section id="speakers" class="section speakers">
        <div class="container">
            <div class="row">
              <div class="col-md-12">
                <h3 class="section-title">Keynote Speakers</h3>
              </div>
            </div>
            <div class="row">
              <div class="col-md-2">
                  <div class="speaker">
                  <figure>
                    <img alt="" class="img-responsive center-block" src="assets/images/speakers/andy.png" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content="Andy will talk about the Mayflower Autonomous Ship project, in which IBM is the technology partner. Mayflower has no captain and no crew, and is a scientific research vessel for gathering data from the ocean to help us understand the impact of climate change and pollution, studying things like microplastics and the health of marine mammals. This fully autonomous boat is scheduled to sail from Plymouth UK to Plymouth Massachusetts, recreating the journey of the Pilgrim Fathers just over 400 years ago. Andy will describe how the AI Captain navigates the ship and talks about some of the scientific experiments on board, and the data these are producing.">
                  </figure>
                </div>
             </div>
             <div class="col-sm-10">
                    <h3>Mayflower Autonomous Ship - the future of autonomous marine exploration</h3>
                    <h4>Andy Stanford-Clark (IBM Corporate Strategy)</h4>
                    <p>Prof Andy Stanford-Clark leads transformational innovation projects for clients in EMEA as part of IBM's Corporate Strategy organisation. He is an IBM Distinguished Engineer, a Master Inventor with more than 40 patents, and is IBM's Quantum Computing leader for the UK. Andy is based at IBM's Hursley Park laboratories near Winchester, and has has been working in the area that we now call the Internet of Things for more than 20 years. He has a BSc in Computing and Mathematics, and a PhD in Computer Science. He is a Visiting Professor at the University of Newcastle, an Honorary Professor at the University of East Anglia, an Adjunct Professor at the University of Southampton, and a Fellow of the British Computer Society.</p>
            </div>
             </div>
          <div class="row">
              <div class="col-md-2">
                  <div class="speaker">
                  <figure>
                    <img alt="" class="img-responsive center-block" src="assets/images/speakers/jrrao.png" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content="Reports of exploits and vulnerabilities at every layer of the systems stack are reflective of a growing trend of increasingly sophisticated attackers and an urgent need for more innovative and effective defenses. Attackers have seized the advantage with the democratization of AI and the ubiquitous availability of computing resources via third party service providers while defenders endeavor to keep pace. The recent Presidential Executive Order on Improving the Nation's Cybersecurity from the current US administration significantly raises the bar on security on both government and commercial IT service providers creating a unique opportunity to infuse new security architectures and technologies into enterprise defenses. The time is ripe for harvesting decades long work in systems security research to implement and deploy confidential computing mechanisms to lay the foundation for zero trust architectures and secure enterprise and cloud environments. In this talk, we will describe the drivers and evolution of both compute-centric and data-centric confidential computing mechansims that were pioneered at IBM Research and discuss the important problems that remain to be solved to realize the promise of these technologies and bring change across the industry.">
                  </figure>
                </div>
             </div>
             <div class="col-sm-10">
               <h3>Systems Security in a Zero Trust World: An Industrial Research Perspective</h3>
               <h4>Josyula R. Rao</h4>
               <p>J.R. Rao is an IBM Fellow and CTO for the Security Research team at IBM. Based at the IBM Thomas. J. Watson Research Center, the global team comprises more than 200 researchers who work in the areas of AI Security, Cybersecurity, Cloud and Systems Security, Information Security and Cryptography. JR works closely with commercial and government customers, academic partners and IBM business units to drive new and innovative technologies into IBM's products and services and definitive industry standards. The goal of his research is to significantly raise the bar on the quality of security while simultaneously easing the overhead of developing and deploying secure solutions. Dr. Rao has published widely in premier security conferences and workshops and holds numerous US and European patents. He is a member of the IBM Academy of Technology, emeritus member of IFIP's Working Group 2.3 (Programming Methodology) and the Industry Advisory Board of the Georgia Tech Information Security Center. Dr. Rao obtained his doctorate degree from the University of Texas at Austin, a Master’s degree in Computer Science from the State University of New York at Stony Brook, and a Bachelor of Technology degree in Electrical Engineering from the Indian Institute of Technology, Kanpur.</p>
            </div>
             </div>
      </div>
    </section>

    <section id="speakers" class="section speakers">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Invited Speakers</h3>
                </div>
            </div>

            <div class="row">
                <div class="col-md-3 col-md-offset-1">
                    <div class="speaker">
                        <figure>
                            <img alt="" title="Bio" class="img-responsive center-block" src="assets/images/speakers/apo.jpg" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content=" Apostolos Kokolis is a PhD student at the University of Illinois, Urbana-Champaign (UIUC) working with prof. Josep Torrellas. His research focuses on the development of computing architectures which ease the adoption of Non-Volatile Memories (NVM) in contemporary systems. Specifically, he has worked on addressing challenges of utilizing NVMs on multi-node distributed systems by creating Distributed Data Persistency models and solving problems of single-node systems such as NVM programming and data placement in hybrid DRAM-NVM systems. Currently, he is working on network support for distributed transactional systems. Apostolos holds an MSc in Computer Science from UIUC and an ECE BSc degree from NTUA, Greece. In the past he has worked as an intern for Facebook, AMD Research and IMEC Research Institute.">
                        </figure>
                        <h4>Apostolos Kokolis</h4>
                        <p>University of Illinois Urbana-Champaign</p> 
                    </div>
                </div>
                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt=""  title="Bio" class="img-responsive center-block" src="assets/images/speakers/jessica.jpg" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content="Jessica is a fourth-year PhD student at MIT, advised by Julian Shun. She is currently interested in designing fast parallel graph mining algorithms, with strong theoretical guarantees and scalable and efficient implementations under unified frameworks. She is particularly interested in clustering and subraph processing and decomposition problems.">
                        </figure>
                        <h4>Jessica Shi</h4>
                        <p>Massachusetts Institute of Technology</p> 
                    </div>
                </div>
                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt=""  title="Bio" class="img-responsive center-block" src="assets/images/speakers/ananda.jpeg" style="border-radius:50%;width:300px" data-toggle="popover" data-container="body" data-placement="top" data-content="Ananda is a Ph.D. student at the Electrical and Computer Engineering (ECE) school at Georgia Institute of Technology. Anand’s research interest includes designing custom architectures for efficient and deep learning systems and continuous learning systems. He has been the author of several papers in top-tier computer architecture conferences. A couple of his papers are honorable mentions in the IEEE MICRO Top picks 2019, and one was awarded the best paper award at HPCA2020.">
                        </figure>
                        <h4>Ananda Samajdar</h4>
                        <p>Georgia Institute of Technology</p> 
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-md-3 col-md-offset-1">
                    <div class="speaker">
                        <figure>
                            <img alt=""  title="Bio" class="img-responsive center-block" src="assets/images/speakers/anirudh.jpg" style="border-radius:50%;width:300px" data-toggle="popover" data-container="body" data-placement="top" data-content="Anirudh Seshadri hails from Chennai, India. In December 2017, he obtained his Bachelor of Technology in Information Technology from Anna University, India. He later joined the graduate program at the Department of Electrical and Computer Engineering, North Carolina State University, in Fall 2018. He is currently a Ph.D. student, working on the project titled 'Post-Fabrication Microarchitecture' under the guidance of Dr. Eric Rotenberg.">
                        </figure>
                        <h4>Anirudh Seshadri</h4>
                        <p>North Carolina State University</p> 
                    </div>
                </div>
                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt=""  title="Bio" class="img-responsive center-block" src="assets/images/speakers/lenjani.jpg" style="border-radius:50%;width:300px" data-toggle="popover" data-container="body" data-placement="top" data-content="Marzieh Lenjani is a last-year Ph.D. student in Computer Science at the University of Virginia, where she is advised by Professor Kevin Skadron. Marzieh’s research explores accelerator design for data-intensive applications, as well as characterization and optimization of applications on emerging devices. Her research has resulted in several publications at premier computer architecture venues (such as ISCA, HPCA, ASPLOS, and IISWC), one published patent, and two patent applications (funded by SRC). Marzieh’s work has been nominated for the best paper award at HPCA'20 and IISWC'19. She has also received the John A. Stankovic Graduate Research Award from the Computer Science Department at the University of Virginia for outstanding research.">
                        </figure>
                        <h4>Marzieh Lenjani</h4>
                        <p>University of Virginia</p>
                    </div>
                </div>
                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt=""  title="Bio" class="img-responsive center-block" src="assets/images/speakers/quanquan.jpg" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content="Quanquan C. Liu recently received her PhD in EECS from MIT where she is currently a postdoctoral scholar, working with Prof. Julian Shun. Her dissertation was advised by Prof. Erik D. Demaine and Prof. Julian Shun. Her current research focuses on parallel and distributed graph algorithms, scheduling algorithms, and dynamic algorithms/data structures. She has worked on a variety of problems in these domains including k-core decompositions, subgraph counting, maximal independent set, (\Delta + 1)-coloring, and near-linear time scheduling. Her other past research interests include cache-efficient and cache-adaptive algorithms/lower bounds, consensus, and memory-hard functions/proofs-of-space/proofs-of-memory. During the summer of 2020 she interned with Google’s discrete algorithms team as a student researcher working on various scheduling and routing algorithms research. Before that she was a summer research intern with the Digital Currency Initiative (with whom she is also currently a collaborator). She will be joining Northwestern’s CS theory group in February 2022 as a postdoctoral scholar.">
                        </figure>
                        <h4>Quanquan Liu</h4>
                        <p>Massachusetts Institute of Technology</p>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-md-3 col-md-offset-1">
                    <div class="speaker">
                        <figure>
                            <img alt=""  title="Bio" class="img-responsive center-block" src="assets/images/speakers/placeholder.png" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content="Sarada Krithivasan received the B.Tech. degree in electrical and electronics engineering from the National Institute of Technology, Tiruchirapalli, India, in 2017. She is currently pursuing the Ph.D. degree in electrical and computer engineering at Purdue University, advised by Prof. Anand Raghunathan. She interned with IBM T. J. Watson Research Center, Yorktown Heights, NY, USA, during the summers of 2020 and 2021. Her current research interests include analyzing the impact of sparse computations in DNNs on energy efficiency and robustness, and designing methodologies for runtime-efficient DNN training. She was awarded with the Ross Fellowship from Purdue University in 2017.">
                        </figure>
                        <h4>Sarada Krithivasan</h4>
                        <p>Purdue University</p>
                    </div>
                </div>
                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt="" title="Bio"  class="img-responsive center-block" src="assets/images/speakers/reena.jpg" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content="Reena Elangovan is a PhD student in the School of Electrical and Computer Engineering, Purdue University, working as a Research Assistant under the guidance of Prof. Anand Raghunathan. She received BTech and MTech degrees in Electrical Engineering from IIT Madras in 2016. From 2016 to 2017, she worked at Texas Instruments as a Digital Design Engineer. Her research interests include efficient architecture design for emerging workloads such as precision-scaling/approximate computing for deep neural networks, and in-memory computations with emerging memory devices.">
                        </figure>
                        <h4>Reena Elangovan</h4>
                        <p>Purdue University</p> 
                    </div>
                </div>
                <div class="col-md-3">
                    <div class="speaker">
                        <figure>
                            <img alt=""  title="Bio" class="img-responsive center-block" src="assets/images/speakers/placeholder.png" style="border-radius:50%;width:300px;" data-toggle="popover" data-container="body" data-placement="top" data-content="Ajay is a 4th year PhD student in the Computer Science and Artificial Intelligence Laboratory (CSAIL), MIT, advised by Prof. Saman Amarasinghe. Ajay's research interests are primarily focused on high-performance DSL design and implementation. His current work is focused on making it easy for domain experts to write DSLs, especially for upcoming architectures. His recent work on 'Compiling Graph Applications for GPUs with GraphIt' won the best paper award at CGO'2021.">
                        </figure>
                        <h4>Ajay Brahmakshatriya</h4>
                        <p>Massachusetts Institute of Technology</p> 
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section id="program" class="section schedule">

        <div class="container">
            <div class="row">
                <div class="col-md-11">
                    <h3 class="section-title">Program</h3>
                    (<em>all times are in Eastern Time</em>)
                    <p>
                    <table class="table table-hover">
                      <thead class="thead-light">
                        <tr>
                          <th colspan=2 scope="col">October 29th<sup></sup>, 2021</th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <th scope="row">8:50 - 9:00am</th>
                          <td>Introduction and Welcoming Remarks</td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">9:00 - 09:45am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Andy will talk about the Mayflower Autonomous Ship project, in which IBM is the technology partner. Mayflower has no captain and no crew, and is a scientific research vessel for gathering data from the ocean to help us understand the impact of climate change and pollution, studying things like microplastics and the health of marine mammals. This fully autonomous boat is scheduled to sail from Plymouth UK to Plymouth Massachusetts, recreating the journey of the Pilgrim Fathers just over 400 years ago. Andy will describe how the AI Captain navigates the ship and talks about some of the scientific experiments on board, and the data these are producing.">
                            <strong>Keynote: Mayflower Autonomous Ship - the future of autonomous marine exploration </strong> <br>
                            Andy Stanford-Clark (IBM Corporate Strategy) </br> </td>
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">09:45 - 10:00am</th>
                          <td><i>Break</i></td>
                        </tr>
                        <tr>
                          <th scope="row">10:00 - 10:30am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Data processing requirements of big data and machine learning applications are outstripping the data transfer capacity of classic Von Neumann architectures. The main area where the current computing paradigm and architecture have lagged is data movement. The transfer of data from where it is stored, the off-chip memory, to where it is analyzed, the processor, takes one order of magnitude more time and consumes two orders of magnitude higher energy than the actual computation (e.g., a single-precision addition). Adding processing units as close as possible to the memory cells, i.e., processing in memory (PIM), alleviates the data movement overhead, unlocking the value of modern applications. However, realizing the true potential of PIM requires rethinking and simplifying the control, access, and communication mechanisms of PIM units. In my talk, I first discuss the inefficacy of traditional MIMD, SIMD, and SIMT architectures for data-intensive applications, with few computations per data element and challenges due to control and access divergence. Then, I introduce our proposed architectures, Fulcrum and FulcrumV2 (Gearbox), that offer a trade-off between (i) full control and access divergence support in MIMD and (ii) no/costly control or divergence support in SIMD/SIMT approaches. We show the flexibility of our design by mapping important kernels from different domains such as machine learning, database management, and graph processing. Finally, I conclude with our vision for identifying common requirements of data-intensive applications, designing a semi-general-purpose PIM-based accelerator (which supports a wide range of applications), and developing a software stack for our accelerator."> Rethinking Control, Access, and Communication Mechanisms for Data-intensive Applications <br> Marzieh Lenjani ( University of Virginia ) </td> 
                        </tr>
                        <tr>
                          <th scope="row">10:30 - 11:00am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="This talk will focus on two broad areas of the research performed by the speaker on efficient DL accelerator design. Designing efficient custom architecture is a costly endeavor, especially in the face of changing workload requirements, e.g., DL workloads. These workloads are often becoming computing-intensive and irregular, rendering the existing acceleration platforms suboptimal and inefficient and prompting new architectural exploration. The first area of the talk will focus on efficient architecture design space exploration for building performant, systolic array-based DL accelerators for specific workloads and design constraints. Specifically, the speaker will present analytical models and the SCALE-Sim simulator to demonstrate their utility in systematically exploring the design space to find the optimal design configurations. In the second half of the talk, the speaker will present recent and ongoing work on leveraging AI techniques to learn the design and mapping space of DNN accelerators. This portion of the talk will demonstrate formulating architecture design space exploration as an ML problem and learning the optimization space to directly predict optimal architecture configuration without search, thus reducing the non-recurring engineering costs when optimizing architecture for new workloads."> AIrchitect: Leveraging AI to build scalable and flexible Deep Learning accelerators <br> Ananda Samajdar ( Georgia Institute of Technology ) </td> 
                        </tr>
                        <tr>
                          <th scope="row">11:00 - 11:30am</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Deep Neural Networks (DNNs) have witnessed widespread success in several machine learning tasks, leading to their deployment in several real-world products and services. This success has been enabled by advancements in the design of hardware platforms such as Graphics Processing Units (GPUs) and accelerators. However, recent trends in state-of-the-art DNNs point to enormous and ever-increasing compute requirements, surpassing the rate of advancements in deep learning hardware. This growing gap between the compute demands and hardware capabilities threatens to stymie progress in the field of machine learning. Creating the next generation of efficient and robust machine learning systems will require hardware-aware design, or consideration of hardware characteristics in the design of the algorithms. My talk broadly characterizes our efforts into two directions, i.e., improving execution efficiency and robustness of  machine learning systems. As part of the first direction of efforts, I will be discussing techniques to improve the training complexity of DNNs through hardware awareness. We first consider the widely-used stochastic gradient descent (SGD) algorithm used for training DNNs. We propose a method to use localized learning, which is computationally cheaper and incurs lower memory footprint, to accelerate an SGD-based training framework with minimal impact on accuracy. This is achieved by employing localized learning in a spatio-temporally selective manner, i.e., in selected network layers and epochs. Next, we consider input interpolation techniques to reduce the effective size of the training dataset every epoch. Specifically, groups of training inputs are combined such that training on the resulting composite sample, has a similar effect on model performance as training on the individual inputs. To preserve accuracy, we propose techniques to mitigate the interference between the features of the constituent inputs in the composite sample. Further, we devise selective interpolation strategies, i.e., only a subset of training inputs are interpolated every epoch. For the second direction of our efforts on robustness, I will be discussing a new challenge identified in the field of adversarial attacks, by proposing attacks that degrade the execution efficiency (energy or time) of a DNN on a given hardware platform. As a specific embodiment of such attacks, we propose sparsity attacks, which perturb the inputs to a DNN so as to result in much lower sparsity within the network, causing it’s latency and energy to be increased on sparsity-optimized hardware platforms. In summary, this talk will demonstrate that hardware-awareness can result in improved performance of deep learning, while also opening up new classes of attacks that must be addressed."> Hardware-Aware Efficient and Robust Deep Learning <br> Sarada Krithivasan ( Purdue University ) </td> 
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">11:30 - 01:30pm</th>
                          <td><i>Lunch Break</i></td>
                        </tr>
                        <tr bgcolor="#EBF5FB">
                          <th scope="row">01:30 - 02:15pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Reports of exploits and vulnerabilities at every layer of the systems stack are reflective of a growing trend of increasingly sophisticated attackers and an urgent need for more innovative and effective defenses. Attackers have seized the advantage with the democratization of AI and the ubiquitous availability of computing resources via third party service providers while defenders endeavor to keep pace. The recent Presidential Executive Order on Improving the Nation's Cybersecurity from the current US administration significantly raises the bar on security on both government and commercial IT service providers creating a unique opportunity to infuse new security architectures and technologies into enterprise defenses. The time is ripe for harvesting decades long work in systems security research to implement and deploy confidential computing mechanisms to lay the foundation for zero trust architectures and secure enterprise and cloud environments. In this talk, we will describe the drivers and evolution of both compute-centric and data-centric confidential computing mechansims that were pioneered at IBM Research and discuss the important problems that remain to be solved to realize the promise of these technologies and bring change across the industry.">
                            <strong>Keynote: Systems Security in a Zero Trust World: An Industrial Research Perspective</strong> <br> Josyula R. Rao (IBM Research) </br> </td>
                        </tr>
                        <tr>
                          <th scope="row">02:15 - 02:30pm</th>
                          <td><i>Break</i></td>
                        </tr>
                        <tr>
                          <th scope="row">02:30 - 03:00pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Deep Neural Networks (DNNs) achieve state-of-the-art performance in a variety of machine learning tasks such as computer vision and natural language processing. The remarkable algorithmic performance of DNNs comes with extremely high computation and storage demands, which outpace the growth in capabilities of commodity hardware. In this talk, I will present our two recent efforts to address this challenge – (i) Approximate computation method to design efficient precision-reconfigurable hardware and (ii) In-Memory computation framework enabled by compact and energy-efficient Piezoelectric FETs (PeFETs). Precision scaling is a popular technique to minimize both the compute and storage requirements of DNNs. Efforts toward creating ultra-low-precision (sub-8-bit) DNNs for efficient inference suggest that the minimum precision required to achieve a given network-level accuracy varies considerably across and within networks, requiring support for variable precision in DNN hardware. Previous proposals such as bit-serial hardware incur high overheads, significantly diminishing the benefits of lower precision. To efficiently support precision re-configurability in DNN accelerators, we introduce an approximate computing method wherein multiply-accumulate computations are performed at the granularity of blocks (a block is a group of bits). We propose approximations to block-wise computation in order to enable precision reconfigurability with low overheads. We show that our framework can achieve significant improvements in system energy and performance with small loss in classification accuracy. The performance and energy-efficiency of data-intensive applications like DNN inference in traditional Von-Neumann architectures are bottlenecked by the slow and energy-intensive data movements between memory and processing unit. In-memory computing is a promising approach that alleviates this bottleneck by computing within memory. Non-volatile memory (NVM) based in-memory computing has gained considerable interest recently due to the desirable characteristics of NVMs such as high density and low-leakage power. Most of the previously proposed NVMs have a major disadvantage – slow and power-hungry current-driven write. Recently, Piezoelectric FETs (PeFETs) have shown considerable potential for efficient future memory hierarchies due to their fast and low-power electric-field driven write. We enhance the PeFET memory cell with ternary compute capability to perform efficient in-memory computation. We demonstrate the benefits of the ternary compute-enabled PeFET cell by performing ternary DNN inference and achieving significant system improvements compared to a well-optimized near-memory SRAM baseline."> Precision Reconfigurable and In-Memory Computing Architectures for Efficient DNN Inference <br> Reena Elangovan ( Purdue University ) </td> 
                        </tr>
                        <tr>
                          <th scope="row">03:00 - 03:30pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Graph clustering and community detection are central problems in modern data mining. The increasing need for analyzing billion-scale data  calls for faster and more scalable algorithms for these problems. There are certain trade-offs between the quality and speed of such clustering algorithms. In this paper, we design scalable algorithms that achieve high quality when evaluated based on ground truth. We develop a generalized sequential and shared-memory parallel framework based on the LambdaCC objective (introduced by Veldt et al.), which encompasses modularity and correlation clustering. Our framework consists of highly-optimized implementations that scale to large data sets of billions of edges and that obtain high-quality clusters compared to ground-truth data, on both unweighted and weighted graphs. Our empirical evaluation shows that this framework improves the state-of-the-art trade-offs between speed and quality of scalable community detection. For example, on a 30-core machine with two-way hyper-threading, our implementations achieve orders of magnitude speedups over other correlation clustering baselines, and up to 28.44x speedups over our own sequential baselines while maintaining or improving quality. "> Scalable Community Detection via Parallel Correlation Clustering <br> Jessica Shi ( Massachusetts Institute of Technology ) </td> 
                        </tr>
                        <tr>
                          <th scope="row">03:30 - 04:00pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Distributed applications such as key-value stores and databases avoid frequent writes to secondary storage devices to minimize performance degradation. They provide fault tolerance by replicating variables in the memories of different nodes, and using data consistency protocols to ensure consistency across replicas. Unfortunately, the reduced data durability guarantees provided can cause data loss or slow data recovery. In this environment, non-volatile memory (NVM) offers the ability to attain both high performance and data durability in distributed applications. However, it is unclear how to tie NVM memory persistency models to the existing data consistency frameworks, and what are the durability guarantees that the combination will offer to distributed applications. In this presentation, I’ll talk about the concept of Distributed Data Persistency (DDP) model, which is the binding of the memory persistency model with the data consistency model in a distributed system. I reason about the interaction between consistency and persistency by using the concepts of Visibility Point and Durability Point. I present the design of low-latency distributed protocols for DDP models that combine five consistency models with five persistency models. For the resulting DDP models, I’ll show the trade-offs between performance, durability, and intuition provided to the programmer."> Distributed Data Persistency <br> Apostolos Kokolis ( University of Illinois Urbana-Champaign ) </td> 
                        </tr>
                        <tr bgcolor="#FEF9E7">
                          <th scope="row">04:00 - 04:15pm</th>
                          <td><i>Break</i></td>
                        </tr>						
                        <tr>
                          <th scope="row">04:15 - 04:45pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="The end of conventional processor scaling has driven research and industry practice to explore a new generation of approaches with rich features and optimizations opportunities especially in the sparse computation domains. One such domain is Graphs which are ubiquitous and taking advantage of the right features is the key to performance. We propose the Unified Graph Framework (UGF) that extends the GraphIt DSL's optimization and code generation techniques to different architectures. UGF achieves portability with reasonable effort by decoupling the architecture-independent algorithm from the architecture-specific backend and schedules. We introduce a new domain-specific intermediate representation, the GraphIR, that is key to this decoupling. The GraphIR encodes high-level algorithm and optimization information needed for hardware-specific code generation, making it easy to develop different backends (GraphVMs) for diverse architectures, including CPUs, GPUs, and next generation hardware such as Swarm and the HammerBlade manycore. Our evaluations show UGF allows optimizations that can improve performance up-to 53x over the default generated code across 5 applications, 9 graphs and 4 architectures. For the GPU GraphVM, UGF generated code is upto 5.11x faster than the next fastest state-of-the-art framework."> Taming the Zoo: A Unified Graph Compiler Framework for Novel Architectures <br> Ajay Brahmakshatriya ( Massachusetts Institute of Technology ) </td> 
                        </tr>
                        <tr>
                          <th scope="row">04:45 - 05:15pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Microarchitectural enhancements that improve performance generally, across many workloads, are favored in superscalar processor design. Targeting general performance is necessary but it is also constraining. We explore relieving this constraint, via a new paradigm called Post-Fabrication Microarchitecture (PFM).  A high-performance superscalar core is coupled with a reconfigurable logic fabric, RF. A programmable interface, or Agent, allows for RF to observe and microarchitecturally intervene at key pipeline stages of the superscalar core. New microarchitectural components, specific to applications, are synthesized on-demand to RF. All instructions still flow through the superscalar pipeline, as usual, but their execution is streamlined (better instructions per cycle (IPC)) through microarchitectural intervention by RF. Our research shows that one can achieve large speedups of individual applications, by analyzing their bottlenecks and providing customized microarchitectural solutions to target these bottlenecks. Examples of PFM use-cases explored in this paper include custom branch predictors and data prefetchers."> Post-Fabrication Microarchitecture <br> Anirudh Seshadri ( North Carolina State University ) </td> 
                        </tr>
                        <tr>
                          <th scope="row">05:15 - 05:45pm</th>
                          <td data-toggle="popover" data-placement="top" data-container="body" data-content="Maintaining a k-core decomposition quickly in a dynamic graph is an important problem in many applications, including social network analytics, graph visualization, centrality measure computations, and community detection algorithms. The main challenge for designing efficient k-core algorithms is that a single change to the graph can cause the decomposition to change significantly. We present the first parallel batch-dynamic algorithm for maintaining an approximate k-core decomposition that is efficient in both theory and practice. Given an initial graph with m edges, and a batch of B updates, our algorithm provably maintains a (2 + c)-approximation of the coreness values for all vertices (for any constant c > 0) in O(B log^2 m) amortized work and O(log^2 m log log m) depth (parallel time) with high probability. We present the first proof of this approximation factor in the dynamic setting under our depth and work bounds in the batch-dynamic setting. We implemented and experimentally evaluated our algorithm on a 30-core machine with two-way hyper-threading on 11 graphs of varying densities and sizes. Compared to the state-of-the-art algorithms, our algorithm achieves up to a 114.52x speedup against the best parallel implementation, up to a 544.22x speedup against the best approximate sequential algorithm, and up to a 723.72x speedup against the best exact sequential algorithm. We also obtain results for our algorithms on graphs that are orders-of-magnitude larger than those used in previous studies.

"> Fast and Scalable Parallel Batch-Dynamic k-Core Decomposition <br> Quanquan Liu ( Massachusetts Institute of Technology ) </td> 
                        </tr>
                        <tr>
                          <th scope="row">05:45</th>
                          <td>Concluding Remarks</td>
                        </tr>
                      </tbody> 
                    </table>
                    </p>
                </div>
            </div>
    </section>

    <section id="org" class="section registration">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Organizers</h3>
                </div>
                <div class="col-md-8">
                <p>
                  <b><a href="https://researcher.watson.ibm.com/researcher/view.php?person=ibm-Sandhya.Koteshwara" rel="nofollow" target="_blank">Sandhya Koteshwara</a></b> is a 
                  Research Staff Member at IBM T J Watson Research Center. Her research interests include secure cloud infrastructure design, embedded system security, 
                  cryptographic hardware and semiconductor supply chain integrity. She obtained her PhD degree from the University of Minnesota with a thesis focused on hardware security. 
                </p>
                <p>
                <b><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-kvswamin" rel="nofollow" 
                    target="_blank">Karthik Swaminathan</a> </b> is a research staff member at the Efficient and Resilient Systems Group at the IBM T.J Watson Research Center. His research has a broad, cross-layer scope examining circuit, architecture and application level optimizations for improving the reliability and energy efficiency of multi core systems and accelerators.  He also works on characterizing performance and reliability of IBM server-class and mainframe processors at various stages of design. He holds a PhD from Penn State University. 
                </p>
                <p>
                <b>David Trilla</b> is a Post-doctoral Researcher at IBM T. J. Watson Research Center. He has worked on real-time systems and current 
                research interests include security and agile hardware development. He obtained his Ph.D. at the Barcelona Supercomputing Center (BSC) granted by 
                the Polytechnic University of Catalonia (UPC), Spain.
                </p>
                <p>
                <b><a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-ajvega" rel="nofollow" target="_blank">Augusto 
                    Vega</a> </b>is a Research Staff Member at IBM T. J. Watson Research Center involved in research and development work in 
                    the areas of highly-reliable power-efficient embedded designs, cognitive systems and mobile computing. He holds M.S. and 
                    Ph.D. degrees from Polytechnic University of Catalonia (UPC), Spain.
                </p>
                <!-- <p>
                <b><a href="https://researcher.watson.ibm.com/researcher/view.php?person=us-xque" rel="nofollow" target="_blank">Xinyu 
                    Que</a> </b> is a Research Staff Member in the Data Centric Systems Co-Design department at the T. J. Watson Research 
                    Center. He received his M.S. degree in Computer Science and Engineering from University of Connecticut and Ph.D. 
                    degrees in Computational Science and Software Engineering from Auburn University. Xinyu has broad interests in high 
                    performance computing and large-scale graph analytics.
                </p> -->
                </div>
            </div>
        </div>
    </section>

    <footer class="site-footer facts">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <p class="site-info">Share this event on your social networks</p>
                </div>
                <div class="col-md-4">
                    <a href="https://twitter.com/home?status=Check%20out%20the%20Workshop%20on%20the%20Future%20of%20Computing%20Architectures%0Ahttps%3A//foca-workshop.org" rel="nofollow" target="_blank"><i class="ion-social-twitter"></i>&nbsp; Twitter</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//foca-workshop.org/" rel="nofollow" target="_blank"><i class="ion-social-facebook"></i>&nbsp; Facebook</a>
                </div>
                <div class="col-md-4">
                    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//foca-workshop.org/&title=Workshop%20on%20the%20Future%20of%20Computing%20Architectures&summary=&source=" rel="nofollow" target="_blank"><i class="ion-social-linkedin-outline"></i>&nbsp; LinkedIn</a>
                </div>
            </div>
        </div>
    </footer>

    <!-- script -->
    <script src="bower_components/jquery/dist/jquery.min.js"></script>
    <script src="bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="bower_components/smooth-scroll/dist/js/smooth-scroll.min.js"></script>
    <script src="assets/js/main.js"></script>
	<script>
	$(document).ready(function(){
		$('[data-toggle="popover"]').popover({
			trigger : 'hover',
			title: 'Abstract',
			html    : true
		});		
	});
	</script>
</body>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-88908704-1', 'auto');
  ga('send', 'pageview');

</script>
  
</html>
